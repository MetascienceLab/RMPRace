{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling for african-american"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'African_American_Names.csv' has been created and modified.\n",
      "Specified keywords have been removed from the file!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "# Define the URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/Lists_of_African_Americans\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Initialize lists to store the extracted first names and last names\n",
    "    first_names = []\n",
    "    last_names = []\n",
    "\n",
    "    # Extract names using regular expressions\n",
    "    name_pattern = re.compile(r'^\\s*([^0-9\\[\\]\\(\\)]+)\\s*$')\n",
    "    for item in soup.find_all(\"li\"):\n",
    "        match = name_pattern.match(item.text.strip())\n",
    "        if match:\n",
    "            name_parts = match.group(1).split()\n",
    "            if len(name_parts) >= 2:\n",
    "                first_name = name_parts[0]\n",
    "                last_name = ' '.join(name_parts[1:])\n",
    "                first_names.append(first_name)\n",
    "                    # Remove quotation marks and anything after the second comma\n",
    "                last_name = last_name.split(',')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(':')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(' - ')[0].strip().replace('\"', '')\n",
    "            \n",
    "                last_names.append(last_name)\n",
    "\n",
    "    # Create a CSV file and write the first names and last names with the \"Category\" column\n",
    "    with open(\"African_American_Names.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"First Name\", \"Last Name\", \"Category\"])\n",
    "        row_counter = 0\n",
    "        for first_name, last_name in zip(first_names, last_names):\n",
    "            # Add \"black\" in the \"Category\" column\n",
    "            if row_counter >= 60 and row_counter < 2164:  # Delete rows 61 to 2163\n",
    "                writer.writerow([first_name, last_name, \"black\"])\n",
    "            row_counter += 1\n",
    "\n",
    "    print(\"CSV file 'African_American_Names.csv' has been created and modified.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the Wikipedia page. Status code:\", response.status_code)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "file_path = \"/Users/eurysohn/Desktop/RA codes/Wikipedia/African_American_Names.csv\"\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of keywords to be removed\n",
    "keywords = ['actress', 'singer', 'rapper', 'and',\"   \", 'pop', \"  \", 'Pop', 'actor', 'Hip hop', 'R&B','the Creator', 'United States' 'comedian', 'Blues', 'Christian hip hop', \"Hip Hop\", \"Hip Hop producer\", \"disc jockey\", \"The Rapper\", \"producer\"]\n",
    "\n",
    "# Function to replace specific words in a text with an empty string\n",
    "def replace_keywords(text):\n",
    "    for keyword in keywords:\n",
    "        text = text.replace(keyword, '')\n",
    "    return text\n",
    "\n",
    "# Iterate over each cell in the DataFrame and apply the function\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: replace_keywords(str(x)))\n",
    "\n",
    "df = df[~df.apply(lambda row: \"African-American\" in str(row), axis=1)]\n",
    "df = df[~df.apply(lambda row: \"African American\" in str(row), axis=1)]\n",
    "df = df[~df.apply(lambda row: \"Beyoncé\" in str(row), axis=1)]\n",
    "\n",
    "def remove_after_dash(cell):\n",
    "    return re.split(r'\\s*[-–—]\\s*', str(cell))[0]\n",
    "\n",
    "# Apply the function to each cell in the DataFrame\n",
    "df = df.applymap(remove_after_dash)\n",
    "\n",
    "# Drop rows where any column has an empty value\n",
    "# Replace empty strings with NaN\n",
    "df.replace([\"\", \" \"], pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows where any cell is NaN\n",
    "df.dropna(inplace=True)\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Specified keywords have been removed from the file!\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl for Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Asian_American_Names.csv' has been created and modified.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "# Define the URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Asian_Americans\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Initialize lists to store the extracted first names and last names\n",
    "    first_names = []\n",
    "    last_names = []\n",
    "\n",
    "    # Extract names using regular expressions\n",
    "    name_pattern = re.compile(r'^\\s*([^0-9\\[\\]\\(\\)]+)\\s*$')\n",
    "    for item in soup.find_all(\"li\"):\n",
    "        match = name_pattern.match(item.text.strip())\n",
    "        if match:\n",
    "            name_parts = match.group(1).split()\n",
    "            if len(name_parts) >= 2:\n",
    "                first_name = name_parts[0]\n",
    "                last_name = ' '.join(name_parts[1:])\n",
    "                first_names.append(first_name)\n",
    "                    # Remove quotation marks and anything after the second comma\n",
    "                last_name = last_name.split(',')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(':')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(' - ')[0].strip().replace('\"', '')\n",
    "            \n",
    "                last_names.append(last_name)\n",
    "\n",
    "# Create a CSV file and write the first names and last names with the \"Category\" column\n",
    "    with open(\"Asian_American_Names.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"First Name\", \"Last Name\", \"Category\"])\n",
    "        row_counter = 0\n",
    "        for first_name, last_name in zip(first_names, last_names):\n",
    "            #Add \"asian\" in the \"Category\" column\n",
    "            if row_counter >= 27 and row_counter < 855:  # Delete rows 61 to 2163\n",
    "                writer.writerow([first_name, last_name, \"asian\"])\n",
    "            row_counter += 1\n",
    "\n",
    "    print(\"CSV file 'Asian_American_Names.csv' has been created and modified.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the Wikipedia page. Status code:\", response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified keywords have been removed from the file!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "file_path = \"/Users/eurysohn/Desktop/RA codes/Asian_American_Names.csv\"\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of keywords to be removed\n",
    "keywords = ['actress', 'singer', 'rapper', 'and',\"   \", \"  \", 'pop','Pop', 'actor', 'Hip hop', 'R&B','the Creator', 'United States' 'comedian', 'Blues', 'Christian hip hop', \"Hip Hop\", \"Hip Hop producer\", \"disc jockey\", \"The Rapper\", \"producer\"]\n",
    "\n",
    "# Function to replace specific words in a text with an empty string\n",
    "def replace_keywords(text):\n",
    "    for keyword in keywords:\n",
    "        text = text.replace(keyword, '')\n",
    "    return text\n",
    "\n",
    "# Iterate over each cell in the DataFrame and apply the function\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: replace_keywords(str(x)))\n",
    "\n",
    "df = df[~df.apply(lambda row: \"Asian-American\" in str(row), axis=1)]\n",
    "df = df[~df.apply(lambda row: \"Asian American\" in str(row), axis=1)]\n",
    "\n",
    "\n",
    "def remove_after_dash(cell):\n",
    "    return re.split(r'\\s*[-–—]\\s*', str(cell))[0]\n",
    "\n",
    "# Apply the function to each cell in the DataFrame\n",
    "df = df.applymap(remove_after_dash)\n",
    "\n",
    "# Drop rows where any column has an empty value\n",
    "# Replace empty strings with NaN\n",
    "df.replace([\"\", \" \"], pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows where any cell is NaN\n",
    "df.dropna(inplace=True)\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Specified keywords have been removed from the file!\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hispanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Hispanic_Names.csv' has been created and modified.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "# Define the URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Hispanic_and_Latino_Americans\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Initialize lists to store the extracted first names and last names\n",
    "    first_names = []\n",
    "    last_names = []\n",
    "\n",
    "    # Extract names using regular expressions\n",
    "    name_pattern = re.compile(r'^\\s*([^0-9\\[\\]\\(\\)]+)\\s*$')\n",
    "    for item in soup.find_all(\"li\"):\n",
    "        match = name_pattern.match(item.text.strip())\n",
    "        if match:\n",
    "            name_parts = match.group(1).split()\n",
    "            if len(name_parts) >= 2:\n",
    "                first_name = name_parts[0]\n",
    "                last_name = ' '.join(name_parts[1:])\n",
    "                first_names.append(first_name)\n",
    "                    # Remove quotation marks and anything after the second comma\n",
    "                last_name = last_name.split(',')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(':')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(' - ')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split(';')[0].strip().replace('\"', '')\n",
    "                last_name = last_name.split('&')[0].strip().replace('\"', '') \n",
    "                last_names.append(last_name)\n",
    "\n",
    "# Create a CSV file and write the first names and last names with the \"Category\" column\n",
    "    with open(\"Hispanic_Names.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"First Name\", \"Last Name\", \"Category\"])\n",
    "        row_counter = 0\n",
    "        for first_name, last_name in zip(first_names, last_names):\n",
    "            #Add \"asian\" in the \"Category\" column\n",
    "            if row_counter >= 103 and row_counter < 529:  # Delete rows 61 to 2163\n",
    "                writer.writerow([first_name, last_name, \"hispanic\"])\n",
    "            row_counter += 1\n",
    "\n",
    "    print(\"CSV file 'Hispanic_Names.csv' has been created and modified.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the Wikipedia page. Status code:\", response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified keywords have been removed from the file!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "file_path = \"/Users/eurysohn/Desktop/RA codes/Hispanic_Names.csv\"\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of keywords to be removed\n",
    "keywords = ['Bachata','from Cypress Hill', 'Writermember of The Diplomats', 'Tejano group', 'pop', 'Grammy', 'from Brooklyn', 'Cuban American', 'Mexican', 'Mexican American', 'actress', 'singer', 'rapper', 'and',\"   \", \"  \", 'Pop', 'actor', 'Hip hop', 'R&B','the Creator', 'United States' 'comedian', 'Blues', 'Christian hip hop', \"Hip Hop\", \"Hip Hop producer\", \"disc jockey\", \"The Rapper\", \"producer\"]\n",
    "\n",
    "# Function to replace specific words in a text with an empty string\n",
    "def replace_keywords(text):\n",
    "    for keyword in keywords:\n",
    "        text = text.replace(keyword, '')\n",
    "    return text\n",
    "\n",
    "# Iterate over each cell in the DataFrame and apply the function\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: replace_keywords(str(x)))\n",
    "\n",
    "\n",
    "\n",
    "def remove_after_dash(cell):\n",
    "    return re.split(r'\\s*[-–—]\\s*', str(cell))[0]\n",
    "\n",
    "# Apply the function to each cell in the DataFrame\n",
    "df = df.applymap(remove_after_dash)\n",
    "\n",
    "# Drop rows where any column has an empty value\n",
    "# Replace empty strings with NaN\n",
    "df.replace([\"\", \" \"], pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows where any cell is NaN\n",
    "df.dropna(inplace=True)\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Specified keywords have been removed from the file!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
